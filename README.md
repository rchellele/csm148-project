# csm148 final project
MAIN DOCUMENT

THE DATA SET
The data set that was used was Laptop Prices, provided by Teaching Assistant, Yihe Deng. Within this dataset, it contained information about various laptops such as their features and corresponding prices. Some of these features ranged from brand type, CPU, RAM, to GPU. Our main variable of interest was the price of laptops in euros, making this our target variable. 

THE OVERVIEW OF THE PROBLEM
The goal of this project is to build a classification model that identifies the price range of a laptop based on its specifications. The price range is categorized into Budget, Mid, and Premium levels. However, given that certain features are categorical while others are numerical, we must understand the relationship between features and prices while also scaling numerical features to maintain consistency. 

THE KEY METHODOLOGY
In this project, the main problem that we aimed to address was building a classification model to predict whether a laptop price would be Budget, Mid, or Premium level based on its specifications. The key methodology that works to solve this problem is a random forest because it works well for both classification and regression. Random forest is an ensemble algorithm that combines many decision trees for classification and regression tasks. Through random forest, it outputs a mean value for the regression model and a mode value for classification. Using Random Forest allows us to analyze the relationship between a laptop’s specifications and price range, while minimizing model variance through ensemble technique. 
Through doing this, we are fulfilling the overall goal of helping customers make informed purchasing decisions, and enabling retailers to price their products more effectively.

RESULTS, CONCLUSIONS, AND LIMITATIONS
The Random Forest Model was fine-tuned using a randomized hyperparameter search which gave the best parameters: {'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 445}. The model performed with a validation accuracy of 82.35% and a weighted F1 score of 0.824 using the best hyperparameters. The confusion matrix displays that the model had a strong performance in classifying laptops into price categories, specifically the Premium category. The misclassifications were mainly between Mid and Budget, and Mid and Premium categories, likely due to overlapping specifications. It is also notable to point out that the categories were unbalanced, as there were more Premium categories compared to Budget and Mid. 
The feature selection process also played a role in optimizing the model performance. Using regression and logistic analysis, features were selected separately on each, and the final set of predictors included features that were shared between the two methods. This selection ensured that only the most significant and consistent features were included in the model. 
Using 5-fold cross validation, the model achieved an average accuracy of 84.3% and an average AUC of 0.952, highlighting its robustness across multiple data splits. Fold-wise accuracies ranged from 80.0% to 87.1%, and its AUC were consistently above 0.94. This shows the model’s strong performance in differentiating between price categories. Class-specific AUC also further proves this, with 0.98 for Budget, 0.90 for Mid, and 0.95 for Premium. 
Additional evaluation metrics include sensitivity and specificity. For the budget category, sensitivity was 61.5%, and specificity was 98.3%. For the Mid category, sensitivity was 79.3% and specificity was 84.4%. For the Premium category, sensitivity was 87.8% and specificity was 87%. These metrics show that for the budget class, with high specificity and low sensitivity, this means the model is cautious in labeling a laptop as Budget, as there are a few false positives but more false negatives. For the mid class, there is more balanced sensitivity and specificity, and the Premium class has the highest and most balanced sensitivity and specificity, which makes sense as in the confusion matrix, it showed the model performed best when identifying premium laptops. ROC Curve analysis was also performed, which showed the Budget ROC curve (AUC 0.98), Mid ROC curve (AUC = 0.90), and ROC curve (0.95). Combined with the specificity and sensitivity, these metrics show the model’s strong ability to classify laptops into price categories.
The Random Forest algorithm was chosen for this project because of its strength in handling numerical and categorical data and its ability to model complex, non-linear relationships. Since it is an ensemble method, it reduces overfitting by averaging predictions from multiple decision trees, balancing accuracy and generalization. Despite this, the model had some limitations. Misclassifications between the Mid-Level and Premium-level categories show room for improvement, as well as the budget categories' high specificity compared to sensitivity. This can be done by feature engineering or fixing the class imbalance. Additionally, the best parameter was 445 trees, but this comes with a computational cost. 
In conclusion, the Random Forest model, combined with feature selection from linear and logistic regression, showed the highest accuracy compared to all other models we tried, making it an effective tool to predict laptop price categories.

HOW TO USE CODE
	To run the code, make sure you have all the required libraries (Pandas, Sckit-learn, Matplotlib, Numpy) installed, before you start executing the script. To use the code, start by making sure the dataset you’d like to use is in a compatible format, like a CSV file, and has all necessary columns. Most importantly, it should include Price_Category (our target variable), and include all necessary columns. Load the dataset into a Pandas Dataframe, and the following code will take care of data exploratory analysis and preprocessing. Data exploratory analysis looks to understand the relationship between features and decide which ones might be important to look at later. It is also to check for missing values or duplicates, though for this project, our dataset was already cleaned. Ensure that column names are clear and descriptive, rename any that aren’t. After that, the rest of the code will take care of preprocessing. It encodes target variables using LabelEncoder, and scales numerical features with StandardScaler to standardize them. For feature selection, both regression and logistic analysis were used to identify the most significant predators, and the final feature list included only ones that were shared between both. The data is then split into training and testing with an 80-20 split.  The Random forest model is trained with hyperparameter tuning through a randomized search, and once theta values are determined, the final model is trained using those parameters. The code evaluates the model using metrics like accuracy, F1 scores, sensitivity, specificity, and AUC, and visualizations such as confusion matrices and ROC curves. If you are using the same dataset and name it the same, the code should all be done and run properly. 

APPENDIX
EXPLORATORY DATA ANALYSIS
Exploratory data analysis was performed to understand the dataset and identify important features, as well as ensure data quality. The dataset was loaded and inspected using .head(), .sample(), and .shape() to check its structure and size. A numerical summary using .describe() showed key statistics for numerical features. Grouping by company showed average laptop prices by brand. Data quality checks showed no missing or duplicated values, confirming the dataset was clean. A histogram visualized the distribution of laptop prices, and showed a larger percentage of the data was in the lower range, with some skewness. A correlation heatmap showed relationships between numerical features and Price_euros, helping show potential important predictors. After EDA, the data was split into training (80%) and testing (20%).

DATA PREPROCESSING AND FEATURE ENGINEERING
Categorical variables were transformed using one-hot encoding for features like OS and TypeName. Boolean variables were transformed to binary values. New features, such as Screen_Area (calculated from screen dimensions), RAM_CPU_Interaction (product of Ram and CPU_freq, which was done because they were the two predictors with the highest correlation to Price_euros, as shown in exploratory data analysis), and Total_storage (sum of primary and secondary storage), were created in attempt to capture potential meaningful interactions. Laptop prices were converted from euros to USD, and categorized into Budget, Mid, and Premium ranges for the target variable. Redundant or unnecessary columns, or columns that may introduce too much noise (Product, CPU_model, GPU_model), were removed. Numerical features were scaled using StandardScaler to ensure consistency.

REGRESSION ANALYSIS
Regression analysis was applied using Linear Regression, which analyzed the relationship between our features, the laptop specifications, and our price categories. The linear regression model was trained on our training set (X_train and y_train) and was tested on our testing set (X_test, y_test). We used evaluation metrics rMSE, MAE, MAD, R2, and correlation to assess our model’s performance in predicting the appropriate price category. We then applied Lasso regularization and analyzed the Lasso coefficients to explain which features have more significant impact on predicting the price categories. Due to measuring several features, regularization was necessary to implement on our model, as it shrunk features that were less relevant to our price point predictions. Without regularization, our model might have assigned large coefficients to less important features, which could then lead to overfitting. If our model was overfitting, it would severely hurt its ability to generalize to new data.
On our training set, our rMSE and MAE scores were relatively low, 0.4226 and 0.3358 respectively. Our low rMSE indicates that the deviation between true and predicted price categories is small, meaning our predictions were generally accurate. Similarly, our low MAE values indicate smaller average error in our price category predictions, meaning again more accurate predictions. Our MAD value on our training set, 0.2754, was also low, suggesting that the magnitude of our errors was quite small and that our predictions were consistent for a majority of our data points. Our correlation coefficient, which was measured to be 0.8141 on our training set, was high. This signifies a strong linear relationship between the true price categories and our predictions. Finally, our R2 score, measured to be 0.6611 on our training set, was moderately high. This shows that around 66% of the variance explained can be attributed to our model, and that our selected features did a reasonably good job of predicting the correct price category. Since our testing values were similar in all five metrics, we can conclude that our model generalizes well.
	Using Lasso regularization, we were able to get the following coefficients for our selected features: RAM (0.153203), CPU_freq (0.148127), TypeName_Notebook (-0.060892), PrimaryStorageType_SSD (0.146613), and Screen_Area (0.074105). We saw that more RAM, faster CPU frequency, and SSDs were our strongest predictors for a higher price point, due to their large non-negative coefficients. Larger screen area was also associated with a higher price, however less so due to the coefficient being closer to zero. Having ‘Notebook’ in the product name lowers the likelihood of falling into the higher priced category, which we know from the non-zero coefficient. However, since the TypeName_Notebook coefficient was close to zero, this feature had less weight on our predictions than our other features. 
** note that it was also used for feature selection, and applied features found in our random forest model at the end of the code

LOGISTIC ANALYSIS
Logistic regression analysis was applied to classify laptops into different price categories (Budget, Mid, Premium). The logistic regression model was trained using the training set (X_train and y_train) and evaluated on the validation set (X_val and y_val). We applied L1 regularization (Lasso) to the model to improve feature selection and reduce overfitting by penalizing less relevant features. This allowed the model to shrink coefficients for less important features to zero, ensuring only the most impactful features were considered in the classification task.
Regularization was necessary in this case, as the dataset likely contained irrelevant or redundant features that could skew the model’s predictions. Without regularization, the model could have assigned disproportionately large coefficients to these less important features, leading to overfitting and poor generalization on unseen data. L1 regularization helped mitigate this risk by performing automatic feature selection, keeping only the most important predictors for the classification of laptop price categories.
From the analysis, we observed that the L1 regularization resulted in a more interpretable model by reducing the number of active features. For example, certain features, such as CPU speed, RAM, or storage type, had non-zero coefficients, indicating their significant role in predicting price categories. On the other hand, some features were shrunk to zero, indicating that they had little to no effect on the classification task.
The evaluation of the model's performance showed an accuracy of 77% on the validation set, which indicates that the model performed reasonably well in predicting the correct price category. The confusion matrix further illustrated that while the model was good at distinguishing the Premium category, it had some challenges with differentiating between the Mid and Budget categories. The confusion matrix compares the true labels with the predicted labels. We used metrics.confusion_matrix to generate it by comparing the true values (y_val_sample) with the predicted values (y_pred_class_l1). The matrix revealed that 39 "Budget" items correctly were classified as Budget, and 22 were misclassified as Mid. 185 "Mid" items were correctly classified as Mid, and 98 were misclassified as Premium. Finally, 359 "Premium" items were correctly classified as Premium, with 49 misclassified as Mid. A predicted probabilities graph was generated in chart form to confirm these findings.
To further assess the robustness of the model, 5-fold cross-validation was applied. This approach divides the data into five subsets, training the model on four subsets and testing it on the remaining one. The process is repeated five times, with each fold serving as the test set once. The results from the cross-validation showed consistent performance across the folds, with AUC scores ranging from 0.925 to 0.949 and accuracy scores between 0.804 and 0.827 for each fold. The average AUC across all folds was 0.934, and the average accuracy was 0.809, indicating that the model generalizes well to different subsets of the data.
These cross-validation results support the validity of the model, suggesting that it is not overfitting and can make reliable predictions on new, unseen data. The consistency across folds demonstrates that the model’s performance is stable and robust, with only slight variation in the metrics across different data splits. Overall, the cross-validation results further confirm that the L1 regularized logistic regression model is effective in classifying laptop price categories and can be trusted for real-world application.
** note that it was also used for feature selection, and applied features found in our random forest model at the end of the code

RANDOM FOREST
Explained in our main report.

PCA AND CLUSTERING
We selected k-means clustering and PCA because they help to group laptops based on shared features and reduce the complexity of the dataset. 
Principal component analysis (PCA) is a dimensionality reduction technique used to alternate a complex dataset with multiple features into a smaller dataset while retaining variance. For this project, PCA was useful in simplifying the features by removing the redundant features that map overlap their information. Through this, noise reduction is reduced and we are able to focus on the influence of more important features which have more variance. By reducing the dimensionality, this ultimately reduces the features and helps create more efficient and accurate clusters. 
K-Means clustering is a clustering algorithm that groups data into k-clusters based on the type of feature and its similarity with others. For this project, k-means clustering was useful in terms of dividing the data into price tiers since it reduces the inner cluster variance. Given that k-means is simple to implement and understand, this is a great method for clustering and finding the patterns with the dataset and its size. 
In the project, we had to begin the data preprocessing by alternating the categorical and numerical features. For the numerical features, we have to scale them by using StandardScaler to maintain consistency of inputs for PCA and k-Means. For the categorical features such as laptop brand and CPU type, we have to encode a value for the features. Then following with PCA, we reduced the dataset’s features into three PCs to capture the majority of variance in the data while also keeping it a lower PCA to enable visualization, which was 78 . By selecting three PCs, this helped maintain data since if we selected two this would’ve led to a loss in variance by 9%. Overall, this PCA method was helpful in our project since it helped address the reduction in the dataset for clustering into groups based on tiers. 
Once we were able to reduce the dimensionality to a PC that maintains the majority of variance, we followed with k-means clustering. For k-means clustering, we used the principal component to cluster the laptops into three price tiers of low, middle, and high; meaning our number of clusters was set to 3 (k = 3). The overall clustering was created based on the mean prices of laptops in each cluster. It should be noted that cluster 0, 1, and 2 represent the prices of laptops from low, middle, and high respectively. Based on the visualizations, the clusters were consistent with the predicted expectations that laptops with a slower CPU and lower RAM were under the low-price cluster. 
The cluster centers from the original feature spaces include RAM, touchscreen, CPU_freq, Total_storage, Screen_AREa, OS_No OS, PrimaryStorageType_SSD, TypeName_Notebook, OS_Linux, GPU_company_Intel, Weight, and IPSpanel; this gives us information for feature selection and what may the potential important predictors to use in our final model.
To test our methods, we added additional metrics to be evaluated. For example, in clustering we added silhouette score to measure how well each data point matched its cluster which we got 0.27. Despite tuning hyperparameters and experimenting with dimensionality reduction, the silhouette score remained low (0.27) suggesting that features overlap and there’s no clear boundary. Given the fixed constraint that k = 3, this limits clustering performance as data begins to overlap. For classification of price tiers, we added a confusion matrix to summarize the performance of classification with values from true positives, true negatives, false positives, and false negatives. In the confusion matrix we got mismatches with the middle tier cases where only 117 instances were correct, compared to 289 misclassified. This could be due to class imbalances, making the model prefer one class over the other. 
So, using PCA with 3 principal components and k-means with 3 distinct clusters, we were able to efficiently address the problem of laptop purchase based on student’s requests. The PCA reduced the dataset for efficient clusters and the k-means grouped the similar features to simplify the classification of price tiers. However, there are limitations given a fixed number of clusters and scaling sensitivity. When having a fixed number of clusters, this requires a specific k-value which is not common in most cases and involves trial and error. When scaling the data, this may cause errors and manipulate values to be incorrect; leading to incorrect clustering and missing data in the total dataset overview. 

NEURAL NETWORK
	Neural network was used to classify laptops into three price categories: Budget, Mid, and Premium. The neural network is trained using a multilayer perceptron, with one hidden layer of 50 neurons and a ReLU activation function. The output layer used a softmax activation function to predict probabilities for each price category. The model was trained using stochastic gradient descent with a learning rate of 0.5, determined through hyperparameter tuning, and a batch size of 100 for 50 epochs. 
	The training and validation accuracy over epochs are shown in the first graph generated. The training accuracy steadily improved, with its highest about 85.3% by the end. The validation accuracy fluctuated a bit, but stabilized around 80% around 30 epochs. The second graph generated in the code shows the mean squared error decreasing over the epochs, showing the model minimized loss during training.
	The best learning rate for the model was 0.5, which was chosen as it trained by choosing the learning accuracy with the highest validation accuracy, which was 80%. We tested multiple learning rates and selected the one with a balance between speed and performance.
	The final test accuracy was 81%, the model generalized pretty well to unseen data. However, it was slightly below the Random Forest accuracy and AUC metrics. This shows the importance of matching model complexity to the dataset, while the neural network performed well, in the end it may be too complex compared to our dataset. 

HYPERPARAMETER TUNING
The Random Forest model was fine-tuned using a randomized hyperparameter search, resulting in the best hyperparameters: {'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 445}. The model achieved a validation accuracy of 82.35% and a weighted F1 score of 0.824 using these parameters. The confusion matrix highlighted the model's ability to classify laptops into price ranges, with strong performance in classifying the Premium category. However, some misclassifications were observed between the Mid and Premium categories, likely due to overlapping features.
For PCA and K-means clustering, hyperparameter tuning focused on determining the optimal number of principal components, rather than clusters (as clusters was predetermined as 3, for the 3 categories of our prices of the target variable). PCA was performed without specifying the number of components, then cumulative variance ratio was calculated to understand how much variance was produced by each principal component. A scree plot was made to visualize this. It is seen that six components explain 90% of the variance, but visualization cannot be done with 6 components. Thuys, 3 components were chosen in order to maximize the explained variance and also allow visualization.
Hyperparmater tuning for the neural network involved optimizing the learning rate. The learning rate controls how much the model’s weights were updated during the training. Multiple values were tested: 0.001, 0.01, 0.05, 0.1, and 0.5. A learning rate of 0.5 had the highest validation accuracy, while showing convergence, which is seen in the training and validation accuracy plots. Thus, this is why we chose it. 








